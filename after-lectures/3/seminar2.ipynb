{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seminar2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_b-iTM8JnDU"
      },
      "source": [
        "import numpy as np\n",
        "def matmul(a, b):\n",
        "    n = a.shape[0]\n",
        "    k = a.shape[1]\n",
        "    m = b.shape[1]  \n",
        "    c = np.zeros((n, m))\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            for s in range(k):\n",
        "                c[i, j] += a[i, s] * b[s, j]\n",
        "                \n",
        "    return c\n",
        "\n",
        "def matmul_isj(a, b):\n",
        "    n = a.shape[0]\n",
        "    k = a.shape[1]\n",
        "    m = b.shape[1]  \n",
        "    c = np.zeros((n, m))\n",
        "    for i in range(n):\n",
        "        for s in range(k):\n",
        "            for j in range(m):\n",
        "                c[i, j] += a[i, s] * b[s, j]\n",
        "                \n",
        "    return c"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4GkytdzJsss"
      },
      "source": [
        "import numpy as np\n",
        "from numba import jit # Just-in-time compiler for Python, see http://numba.pydata.org \n",
        "\n",
        "@jit(nopython=True)\n",
        "def numba_matmul(a, b):\n",
        "    n = a.shape[0]\n",
        "    k = a.shape[1]\n",
        "    m = b.shape[1]\n",
        "    c = np.zeros((n, m))\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            for s in range(k):\n",
        "                c[i, j] += a[i, s] * b[s, j]\n",
        "    return c\n",
        "\n",
        "@jit(nopython=True)\n",
        "def numba_matmul_isj(a, b):\n",
        "    n = a.shape[0]\n",
        "    k = a.shape[1]\n",
        "    m = b.shape[1]\n",
        "    c = np.zeros((n, m))\n",
        "    for i in range(n):\n",
        "        for s in range(k):\n",
        "            mult = a[i, s]\n",
        "            for j in range(m):\n",
        "                c[i, j] += mult * b[s, j]\n",
        "    return c"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM_cuWTCJviq",
        "outputId": "271b3d2c-335b-43ff-ff56-8ff910641562"
      },
      "source": [
        "n = 500\n",
        "a = np.random.randn(n, n)\n",
        "b = np.random.randn(n, n)\n",
        "\n",
        "# %timeit matmul(a, b)\n",
        "# %timeit matmul_isj(a, b)\n",
        "%timeit numba_matmul(a, b)\n",
        "%timeit numba_matmul_isj(a, b)\n",
        "%timeit np.dot(a, b)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 168 ms per loop\n",
            "The slowest run took 7.12 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 38.2 ms per loop\n",
            "100 loops, best of 5: 7.87 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw8CA-iwJykZ"
      },
      "source": [
        "A = np.array([[1, 2, 3], [5, 2, 7]], order=\"C\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCFWPrUwYdsi",
        "outputId": "f901af80-22b1-49ce-d516-5971685f7071"
      },
      "source": [
        "A.dtype"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZaRIUPjYrVj"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "727_6FQOaRaP"
      },
      "source": [
        "A = torch.from_numpy(a)\n",
        "B = torch.from_numpy(b)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "1mb6LAYsa8VQ",
        "outputId": "22fff340-7244-4c6e-fc42-870866e190e1"
      },
      "source": [
        "# How to call BLAS/LAPACK functions from torch \n",
        "torch.__config__.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'PyTorch built with:\\n  - GCC 7.3\\n  - C++ Version: 201402\\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\\n  - NNPACK is enabled\\n  - CPU capability usage: AVX2\\n  - CUDA Runtime 11.1\\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\\n  - CuDNN 8.0.5\\n  - Magma 2.5.2\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \\n'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hFEr2pHk7xM"
      },
      "source": [
        "Search section BLAS and LAPACK Operations in https://pytorch.org/docs/1.10.0/torch.html \n",
        "\n",
        "You will have some strange acronyms like\n",
        "- ```geqrf```\n",
        "- ```ger```\n",
        "- ```ormqr```\n",
        "- etc...\n",
        "\n",
        "These names come from native LAPACK package and are standard for implementation of more complicated algorityhmes from the simple primitives. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaiDVFcgazNt",
        "outputId": "29da3668-db65-46ee-98d7-57dcac587395"
      },
      "source": [
        "%timeit A @ B"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 10.87 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100 loops, best of 5: 6.76 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INM-Vh3_bV0v",
        "outputId": "6af78ae8-9dd4-415e-82b0-3dcc1300bb73"
      },
      "source": [
        "A_gpu = A.to(\"cuda\")\n",
        "B_gpu = B.to(\"cuda\")\n",
        "%timeit A_gpu @ B_gpu"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 177.63 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000 loops, best of 5: 366 Âµs per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re58mfKlaf58",
        "outputId": "bd1d87a3-a837-4af7-a953-616f57df62d9"
      },
      "source": [
        "print(A)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2076,  0.2286, -0.1727,  ..., -1.3513,  0.6674,  0.7101],\n",
            "        [-0.5689,  0.7661,  0.6888,  ..., -1.0185,  0.2321,  1.0647],\n",
            "        [-0.5084,  1.0221,  0.5718,  ..., -1.0592, -2.0717,  0.5223],\n",
            "        ...,\n",
            "        [-0.1754, -0.1383,  1.0748,  ..., -0.0469, -0.1058, -0.9498],\n",
            "        [-0.6619,  0.5752, -0.1461,  ...,  1.6014, -1.0753,  1.8088],\n",
            "        [ 0.6649,  0.0372, -1.6637,  ...,  0.2114,  0.2700, -0.6503]],\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv3bjlmyagsx",
        "outputId": "afdff648-c566-4560-e551-4d654f773ca3"
      },
      "source": [
        "t = torch.randn((n, n))\n",
        "print(t)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.8519, -0.8576,  1.4654,  ..., -0.3948, -1.4546, -1.8130],\n",
            "        [ 0.5388,  0.3280, -1.3981,  ..., -2.4956,  1.3326,  0.1441],\n",
            "        [-1.4787, -0.4034,  0.9097,  ..., -1.2501,  0.2794,  0.7110],\n",
            "        ...,\n",
            "        [ 0.8301, -2.0607, -0.6245,  ..., -0.5105, -1.2650, -1.3490],\n",
            "        [-1.5284,  0.4654,  1.0024,  ..., -0.1602,  1.3207, -0.6443],\n",
            "        [-1.3054,  0.6352, -0.6033,  ...,  0.4865, -1.4938, -1.9792]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpPE85sKap74",
        "outputId": "af07451b-dbad-42f9-b2a1-54d60bc6bcac"
      },
      "source": [
        "t.dtype"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Unym7fqqatRy",
        "outputId": "628ceb43-c4e8-4317-a45e-edf4fb93f052"
      },
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "from jax.config import config\n",
        "config.update(\"jax_enable_x64\", True)\n",
        "\n",
        "A_jax = jnp.array(a)\n",
        "B_jax = jnp.array(b)\n",
        "%timeit (A_jax @ B_jax).block_until_ready()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 loops, best of 5: 457 Âµs per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqQvHRkBcnUs",
        "outputId": "0c8ae3ac-ae7c-4a92-a978-e81a6067d8c3"
      },
      "source": [
        "A_jax.device_buffer.device()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GpuDevice(id=0, process_index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efftlkSqmCL-",
        "outputId": "366661e6-686b-4fa5-bbc6-b18b0d53a78a"
      },
      "source": [
        "A_jax.dtype"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}